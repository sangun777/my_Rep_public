{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28-8. 프로젝트 : 개구리는 안돼요(CIFAR-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이번 프로젝트는 CIFAR-10 데이터셋에 대해 진행\n",
    "* 만들어야 할 모델은 CIFAR-10의 10가지 클래스 중 개구리 라벨을 이상 데이터로 처리하는 모델\n",
    "* 혹시 개구리가 출현할 경우 이를 감지하여 이상감지 경고를 발생시키는 개구리 감지 모델\n",
    "\n",
    "다음의 순서을 따라 진행해 주세요.\n",
    "\n",
    "1. 이상감지용 데이터셋 구축 (개구리 데이터를 학습데이터셋에서 제외하여 테스트 데이터셋에 포함)\n",
    "2. Skip-GANomaly 모델의 구현\n",
    "3. 모델의 학습과 검증\n",
    "4. 검증 결과의 시각화 (정상-이상 데이터의 anomaly score 분포 시각화, 적절한 threshold에 따른 이삼감지율 계산, 감지 성공/실패사례 시각화 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "from scipy.interpolate import interp1d\n",
    "from inspect import signature\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * cifar10 data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_data = (train_data - 127.5) / 127.5\n",
    "test_data = (test_data - 127.5) / 127.5\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# padding to 32 X 32\n",
    "train_data_32 = np.zeros((train_data.shape[0], 32, 32)).astype('float32')\n",
    "test_data_32 = np.zeros((test_data.shape[0], 32, 32)).astype('float32')     \n",
    "# train_data_32[:, 2:30, 2:30] = train_data\n",
    "# test_data_32[:, 2:30, 2:30] = test_data\n",
    "\n",
    "# # 1channel data reshape\n",
    "# train_data = train_data_32.reshape(train_data_32.shape[0], 32, 32, 3).astype('float32')\n",
    "# test_data = test_data_32.reshape(test_data_32.shape[0], 32, 32, 3).astype('float32')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_data[i])\n",
    "#     plt.imshow(train_data[i].reshape(32, 32), cmap='gray')\n",
    "    plt.title(f'index: {i}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels(labels):\n",
    "    new_t_labels = []\n",
    "    for old_label in labels:\n",
    "        if old_label == 6:   # frog:6\n",
    "            new_t_labels.append([0])  # Bag을 이상치로 처리\n",
    "        else:\n",
    "            new_t_labels.append([1])  # 그 외의 경우는 정상치\n",
    "             \n",
    "    return np.array(new_t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bol_train_labels = set_labels(train_labels)\n",
    "bol_test_labels = set_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = []\n",
    "normal_labels = []\n",
    "anomaly_data = []\n",
    "anomaly_labels = []\n",
    "for data, label in zip(train_data, bol_train_labels):\n",
    "    if label == 0:\n",
    "        anomaly_data.append(data)\n",
    "        anomaly_labels.append(label)\n",
    "    else:\n",
    "        normal_data.append(data)\n",
    "        normal_labels.append(label)\n",
    "        \n",
    "normal_data = np.array(normal_data)\n",
    "normal_labels = np.array(normal_labels)\n",
    "anomaly_data = np.array(anomaly_data)\n",
    "anomaly_labels = np.array(anomaly_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3) (45000, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(normal_data.shape, normal_labels.shape)\n",
    "print(anomaly_data.shape, anomaly_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normal_data\n",
    "bol_train_labels = normal_labels\n",
    "test_data = tf.concat([test_data, anomaly_data], 0)\n",
    "bol_test_labels = tf.concat([bol_test_labels, anomaly_labels], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3) (45000, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(normal_data.shape, normal_labels.shape)\n",
    "print(anomaly_data.shape, anomaly_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 1)\n",
      "(15000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(bol_train_labels.shape)\n",
    "print(bol_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for label in bol_train_labels:\n",
    "    if label == 0:\n",
    "        print(label)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, bol_train_labels))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, bol_test_labels))\n",
    "test_dataset = test_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Generator는 U-net 구조를 따름\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_block(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.conv_layer = tf.keras.Sequential([\n",
    "            layers.Conv2D(num_filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                          kernel_initializer=tf.random_normal_initializer(0., 0.02)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        outputs = self.conv_layer(inputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_T_block(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(Conv_T_block, self).__init__()\n",
    "        self.conv_T_layer = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(num_filters, 3, strides=2, padding='same', use_bias=False,\n",
    "                                   kernel_initializer=tf.random_normal_initializer(0., 0.02)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs, concat, training=False):\n",
    "        upsample = self.conv_T_layer(inputs)\n",
    "        outputs = tf.concat([upsample, concat], -1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, num_output_channel=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder_1 = Conv_block(64) # 16\n",
    "        self.encoder_2 = Conv_block(128) # 8\n",
    "        self.encoder_3 = Conv_block(256) # 4\n",
    "        self.encoder_4 = Conv_block(512) # 2\n",
    "        \n",
    "        self.center = Conv_block(512) # 1\n",
    "        \n",
    "        self.decoder_4 = Conv_T_block(512) # 2\n",
    "        self.decoder_3 = Conv_T_block(256) # 4\n",
    "        self.decoder_2 = Conv_T_block(128) # 8\n",
    "        self.decoder_1 = Conv_T_block(64) # 16\n",
    "        \n",
    "        self.output_layer = layers.Conv2DTranspose(num_output_channel, 1, strides=2, padding='same', use_bias=False, # 32\n",
    "                                                   kernel_initializer=tf.random_normal_initializer(0., 0.02))\n",
    "                \n",
    "    def call(self, inputs, training=False):\n",
    "        en_1 = self.encoder_1(inputs) # gen\n",
    "        en_2 = self.encoder_2(en_1)\n",
    "        en_3 = self.encoder_3(en_2)\n",
    "        en_4 = self.encoder_4(en_3)\n",
    "        \n",
    "        center = self.center(en_4)\n",
    "        \n",
    "        de_4 = self.decoder_4(center, en_4)\n",
    "        de_3 = self.decoder_3(de_4, en_3)\n",
    "        de_2 = self.decoder_2(de_3, en_2)\n",
    "        de_1 = self.decoder_1(de_2, en_1)\n",
    "        \n",
    "        outputs = self.output_layer(de_1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Discriminator도 Generator처럼 Conv_block을 활용\n",
    " * 최종적으로 sigmoid를 거쳐 0~1 사이의 숫자를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.encoder_1 = Conv_block(64) # 16\n",
    "        self.encoder_2 = Conv_block(128) # 8\n",
    "        self.encoder_3 = Conv_block(256) # 4\n",
    "        self.encoder_4 = Conv_block(512) # 2\n",
    "        \n",
    "        self.center = Conv_block(100) # 1\n",
    "        \n",
    "        self.outputs = layers.Conv2D(1, 3, strides=1, padding='same',\n",
    "                                          use_bias=False, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        en_1 = self.encoder_1(inputs) # dis\n",
    "        en_2 = self.encoder_2(en_1)\n",
    "        en_3 = self.encoder_3(en_2)\n",
    "        en_4 = self.encoder_4(en_3)\n",
    "        \n",
    "        center = self.center(en_4)\n",
    "        \n",
    "        outputs = self.outputs(center)\n",
    "        \n",
    "        return outputs, center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 모델 구성\n",
    "\n",
    " * Generator와 Discriminator을 합쳐 전체 모델을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()  # Generator가 32X32X1 짜리 이미지를 생성해야 합니다. \n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss 함수\n",
    "\n",
    " * GAN 모델의 핵심은 Loss 함수의 구성방법임\n",
    " * Skip-GANomaly는 이전 모델들과 달리 일반적인 GAN의 학습 절차와 같은 형태의 Loss 구성이 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_loss = tf.keras.losses.MeanSquaredError()\n",
    "l1_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(pred_real, pred_fake):\n",
    "    real_loss = cross_entropy(tf.ones_like(pred_real), pred_real)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(pred_fake), pred_fake)\n",
    "    \n",
    "    total_dis_loss = (real_loss + fake_loss) * 0.5\n",
    "    \n",
    "    return total_dis_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 아래 Generator Loss에는 이전 스텝에서 설명했던 Skip-GANomaly의 주요 loss 함수들이 포함되어 있음을 주목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(real_output, fake_output, input_data, gen_data, latent_first, latent_sec):\n",
    "    w_adv = 1.\n",
    "    w_context = 40.\n",
    "    w_encoder = 1.\n",
    "    \n",
    "    adv_loss = cross_entropy(real_output, fake_output)\n",
    "    context_loss = l1_loss(input_data, gen_data)\n",
    "    encoder_loss = l2_loss(latent_first, latent_sec)\n",
    "    \n",
    "    total_gen_loss = w_adv * adv_loss + \\\n",
    "                     w_context * context_loss + \\\n",
    "                     w_encoder * encoder_loss\n",
    "    \n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 설정\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-3, 0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-3, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습과 평가\n",
    "\n",
    "### Model Train\n",
    "\n",
    " * 모델 학습(총 25Epoch 대략 1시간 정도 소요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(images, training=True)\n",
    "        \n",
    "        pred_real, feat_real = discriminator(images, training=True)\n",
    "        pred_fake, feat_fake = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(pred_real, pred_fake,\n",
    "                                  images, generated_images,\n",
    "                                  feat_real, feat_fake)\n",
    "\n",
    "        disc_loss = discriminator_loss(pred_real, pred_fake)        \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_path = os.path.join(os.getenv('HOME'),'aiffel/ganomaly_skip_no_norm/ckpt')\n",
    "\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 100, \t Total Gen Loss : 20.564992904663086, \t Total Dis Loss : 0.0657399371266365\n",
      "Steps : 200, \t Total Gen Loss : 19.48797035217285, \t Total Dis Loss : 0.07077478617429733\n",
      "Steps : 300, \t Total Gen Loss : 17.96833038330078, \t Total Dis Loss : 0.029569678008556366\n",
      "Steps : 400, \t Total Gen Loss : 18.0872745513916, \t Total Dis Loss : 0.10709141194820404\n",
      "Steps : 500, \t Total Gen Loss : 18.820566177368164, \t Total Dis Loss : 0.050186291337013245\n",
      "Steps : 600, \t Total Gen Loss : 16.895036697387695, \t Total Dis Loss : 0.05767148733139038\n",
      "Steps : 700, \t Total Gen Loss : 17.987316131591797, \t Total Dis Loss : 0.019682899117469788\n",
      "Steps : 800, \t Total Gen Loss : 21.32130241394043, \t Total Dis Loss : 0.00723644532263279\n",
      "Steps : 900, \t Total Gen Loss : 21.35956382751465, \t Total Dis Loss : 0.04263981804251671\n",
      "Steps : 1000, \t Total Gen Loss : 20.344135284423828, \t Total Dis Loss : 0.009212363511323929\n",
      "Steps : 1100, \t Total Gen Loss : 22.68040657043457, \t Total Dis Loss : 0.00827875453978777\n",
      "Steps : 1200, \t Total Gen Loss : 20.90276336669922, \t Total Dis Loss : 0.00592968100681901\n",
      "Steps : 1300, \t Total Gen Loss : 19.468151092529297, \t Total Dis Loss : 0.030293188989162445\n",
      "Steps : 1400, \t Total Gen Loss : 22.668630599975586, \t Total Dis Loss : 0.011544713750481606\n",
      "Steps : 1500, \t Total Gen Loss : 19.05991554260254, \t Total Dis Loss : 0.04607577621936798\n",
      "Steps : 1600, \t Total Gen Loss : 19.735952377319336, \t Total Dis Loss : 0.004152372479438782\n",
      "Steps : 1700, \t Total Gen Loss : 22.695234298706055, \t Total Dis Loss : 0.01153586246073246\n",
      "Steps : 1800, \t Total Gen Loss : 20.242834091186523, \t Total Dis Loss : 0.008059510961174965\n",
      "Steps : 1900, \t Total Gen Loss : 22.285396575927734, \t Total Dis Loss : 0.005132993217557669\n",
      "Steps : 2000, \t Total Gen Loss : 22.373613357543945, \t Total Dis Loss : 0.019999917596578598\n",
      "Steps : 2100, \t Total Gen Loss : 22.71770477294922, \t Total Dis Loss : 0.014905874617397785\n",
      "Steps : 2200, \t Total Gen Loss : 23.6165771484375, \t Total Dis Loss : 0.006878497079014778\n",
      "Steps : 2300, \t Total Gen Loss : 21.52639389038086, \t Total Dis Loss : 0.014518403448164463\n",
      "Steps : 2400, \t Total Gen Loss : 22.151756286621094, \t Total Dis Loss : 0.003646776545792818\n",
      "Steps : 2500, \t Total Gen Loss : 23.03559684753418, \t Total Dis Loss : 0.005252940580248833\n",
      "Steps : 2600, \t Total Gen Loss : 20.313522338867188, \t Total Dis Loss : 0.009419810026884079\n",
      "Steps : 2700, \t Total Gen Loss : 21.195972442626953, \t Total Dis Loss : 0.0022319958079606295\n",
      "Steps : 2800, \t Total Gen Loss : 21.814531326293945, \t Total Dis Loss : 0.019764311611652374\n",
      "Steps : 2900, \t Total Gen Loss : 18.7005615234375, \t Total Dis Loss : 0.03337731957435608\n",
      "Steps : 3000, \t Total Gen Loss : 21.19904136657715, \t Total Dis Loss : 0.04165373742580414\n",
      "Steps : 3100, \t Total Gen Loss : 22.667346954345703, \t Total Dis Loss : 0.04101957753300667\n",
      "Steps : 3200, \t Total Gen Loss : 23.12282943725586, \t Total Dis Loss : 0.005644750781357288\n",
      "Steps : 3300, \t Total Gen Loss : 21.60370445251465, \t Total Dis Loss : 0.006221435964107513\n",
      "Steps : 3400, \t Total Gen Loss : 20.16488265991211, \t Total Dis Loss : 0.027027931064367294\n",
      "Steps : 3500, \t Total Gen Loss : 20.306657791137695, \t Total Dis Loss : 0.010272569954395294\n",
      "Steps : 3600, \t Total Gen Loss : 21.69727897644043, \t Total Dis Loss : 0.005382409319281578\n",
      "Steps : 3700, \t Total Gen Loss : 20.266801834106445, \t Total Dis Loss : 0.007372194901108742\n",
      "Steps : 3800, \t Total Gen Loss : 17.558147430419922, \t Total Dis Loss : 0.04038923606276512\n",
      "Steps : 3900, \t Total Gen Loss : 19.4814395904541, \t Total Dis Loss : 0.007345322519540787\n",
      "Steps : 4000, \t Total Gen Loss : 20.209674835205078, \t Total Dis Loss : 0.007881715893745422\n",
      "Steps : 4100, \t Total Gen Loss : 20.99263572692871, \t Total Dis Loss : 0.006530274171382189\n",
      "Steps : 4200, \t Total Gen Loss : 22.612253189086914, \t Total Dis Loss : 0.03620737046003342\n",
      "Steps : 4300, \t Total Gen Loss : 23.71783447265625, \t Total Dis Loss : 0.022084014490246773\n",
      "Steps : 4400, \t Total Gen Loss : 25.612287521362305, \t Total Dis Loss : 0.005042863078415394\n",
      "Steps : 4500, \t Total Gen Loss : 21.631864547729492, \t Total Dis Loss : 0.0026140406262129545\n",
      "Steps : 4600, \t Total Gen Loss : 24.133577346801758, \t Total Dis Loss : 0.0029334528371691704\n",
      "Steps : 4700, \t Total Gen Loss : 24.400583267211914, \t Total Dis Loss : 0.007727804593741894\n",
      "Steps : 4800, \t Total Gen Loss : 26.363094329833984, \t Total Dis Loss : 0.03885285183787346\n",
      "Steps : 4900, \t Total Gen Loss : 22.755481719970703, \t Total Dis Loss : 0.062449678778648376\n",
      "Steps : 5000, \t Total Gen Loss : 21.53975486755371, \t Total Dis Loss : 0.011713074520230293\n",
      "Steps : 5100, \t Total Gen Loss : 23.488157272338867, \t Total Dis Loss : 0.009796719066798687\n",
      "Steps : 5200, \t Total Gen Loss : 21.947187423706055, \t Total Dis Loss : 0.004182748030871153\n",
      "Steps : 5300, \t Total Gen Loss : 22.49203109741211, \t Total Dis Loss : 0.057053446769714355\n",
      "Steps : 5400, \t Total Gen Loss : 21.385862350463867, \t Total Dis Loss : 0.0038126397412270308\n",
      "Steps : 5500, \t Total Gen Loss : 25.451271057128906, \t Total Dis Loss : 0.00528713408857584\n",
      "Steps : 5600, \t Total Gen Loss : 22.936588287353516, \t Total Dis Loss : 0.0038189429324120283\n",
      "Time for epoch 1 is 299.396831035614 sec\n",
      "Steps : 5700, \t Total Gen Loss : 19.24980354309082, \t Total Dis Loss : 0.003627295373007655\n",
      "Steps : 5800, \t Total Gen Loss : 21.08821678161621, \t Total Dis Loss : 0.002177378162741661\n",
      "Steps : 5900, \t Total Gen Loss : 19.310985565185547, \t Total Dis Loss : 0.006163087673485279\n",
      "Steps : 6000, \t Total Gen Loss : 21.961238861083984, \t Total Dis Loss : 0.006858369335532188\n",
      "Steps : 6100, \t Total Gen Loss : 17.71271514892578, \t Total Dis Loss : 0.015887802466750145\n",
      "Steps : 6200, \t Total Gen Loss : 21.393795013427734, \t Total Dis Loss : 0.004488527309149504\n",
      "Steps : 6300, \t Total Gen Loss : 19.527257919311523, \t Total Dis Loss : 0.01649521104991436\n",
      "Steps : 6400, \t Total Gen Loss : 24.82059097290039, \t Total Dis Loss : 0.007785050198435783\n",
      "Steps : 6500, \t Total Gen Loss : 22.03603744506836, \t Total Dis Loss : 0.003218911588191986\n",
      "Steps : 6600, \t Total Gen Loss : 23.311246871948242, \t Total Dis Loss : 0.00633683055639267\n",
      "Steps : 6700, \t Total Gen Loss : 23.28752899169922, \t Total Dis Loss : 0.005610331892967224\n",
      "Steps : 6800, \t Total Gen Loss : 23.538501739501953, \t Total Dis Loss : 0.005289884749799967\n",
      "Steps : 6900, \t Total Gen Loss : 23.421724319458008, \t Total Dis Loss : 0.0037577205803245306\n",
      "Steps : 7000, \t Total Gen Loss : 23.754281997680664, \t Total Dis Loss : 0.004065344110131264\n",
      "Steps : 7100, \t Total Gen Loss : 24.85009765625, \t Total Dis Loss : 0.005445726215839386\n",
      "Steps : 7200, \t Total Gen Loss : 21.950115203857422, \t Total Dis Loss : 0.0014910583849996328\n",
      "Steps : 7300, \t Total Gen Loss : 19.938169479370117, \t Total Dis Loss : 0.008306168019771576\n",
      "Steps : 7400, \t Total Gen Loss : 24.4106388092041, \t Total Dis Loss : 0.0012941870372742414\n",
      "Steps : 7500, \t Total Gen Loss : 25.0750675201416, \t Total Dis Loss : 0.001103849383071065\n",
      "Steps : 7600, \t Total Gen Loss : 24.69374656677246, \t Total Dis Loss : 0.0017285788198933005\n",
      "Steps : 7700, \t Total Gen Loss : 22.327495574951172, \t Total Dis Loss : 0.003110162913799286\n",
      "Steps : 7800, \t Total Gen Loss : 21.41340446472168, \t Total Dis Loss : 0.007895276881754398\n",
      "Steps : 7900, \t Total Gen Loss : 21.041872024536133, \t Total Dis Loss : 0.0048238858580589294\n",
      "Steps : 8000, \t Total Gen Loss : 19.4588623046875, \t Total Dis Loss : 0.004620802588760853\n",
      "Steps : 8100, \t Total Gen Loss : 24.024473190307617, \t Total Dis Loss : 0.0022972675506025553\n",
      "Steps : 8200, \t Total Gen Loss : 23.520158767700195, \t Total Dis Loss : 0.0020611160434782505\n",
      "Steps : 8300, \t Total Gen Loss : 23.059551239013672, \t Total Dis Loss : 0.004331786185503006\n",
      "Steps : 8400, \t Total Gen Loss : 24.142419815063477, \t Total Dis Loss : 0.01051664724946022\n",
      "Steps : 8500, \t Total Gen Loss : 22.173492431640625, \t Total Dis Loss : 0.0012775528011843562\n",
      "Steps : 8600, \t Total Gen Loss : 21.280193328857422, \t Total Dis Loss : 0.03056708723306656\n",
      "Steps : 8700, \t Total Gen Loss : 23.930469512939453, \t Total Dis Loss : 0.002952195703983307\n",
      "Steps : 8800, \t Total Gen Loss : 23.407245635986328, \t Total Dis Loss : 0.003863271325826645\n",
      "Steps : 8900, \t Total Gen Loss : 20.710494995117188, \t Total Dis Loss : 0.0032867263071238995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 9000, \t Total Gen Loss : 22.24791717529297, \t Total Dis Loss : 0.0009502823813818395\n",
      "Steps : 9100, \t Total Gen Loss : 22.989059448242188, \t Total Dis Loss : 0.006876026280224323\n",
      "Steps : 9200, \t Total Gen Loss : 20.594064712524414, \t Total Dis Loss : 0.0023791957646608353\n",
      "Steps : 9300, \t Total Gen Loss : 23.47322654724121, \t Total Dis Loss : 0.004483907483518124\n",
      "Steps : 9400, \t Total Gen Loss : 23.7493953704834, \t Total Dis Loss : 0.007385968696326017\n",
      "Steps : 9500, \t Total Gen Loss : 20.801794052124023, \t Total Dis Loss : 0.0018227086402475834\n",
      "Steps : 9600, \t Total Gen Loss : 19.941381454467773, \t Total Dis Loss : 0.0023810085840523243\n",
      "Steps : 9700, \t Total Gen Loss : 19.82233428955078, \t Total Dis Loss : 0.0019157397327944636\n",
      "Steps : 9800, \t Total Gen Loss : 20.534713745117188, \t Total Dis Loss : 0.00527633260935545\n",
      "Steps : 9900, \t Total Gen Loss : 24.230140686035156, \t Total Dis Loss : 0.0012544840574264526\n",
      "Steps : 10000, \t Total Gen Loss : 21.464881896972656, \t Total Dis Loss : 0.0018546768696978688\n",
      "Steps : 10100, \t Total Gen Loss : 23.716943740844727, \t Total Dis Loss : 0.00108530989382416\n",
      "Steps : 10200, \t Total Gen Loss : 22.2044677734375, \t Total Dis Loss : 0.0012489487417042255\n",
      "Steps : 10300, \t Total Gen Loss : 19.910633087158203, \t Total Dis Loss : 0.0010252450592815876\n",
      "Steps : 10400, \t Total Gen Loss : 21.668561935424805, \t Total Dis Loss : 0.001592978835105896\n",
      "Steps : 10500, \t Total Gen Loss : 20.82491111755371, \t Total Dis Loss : 0.031341537833213806\n",
      "Steps : 10600, \t Total Gen Loss : 23.324247360229492, \t Total Dis Loss : 0.056031499058008194\n",
      "Steps : 10700, \t Total Gen Loss : 28.22640609741211, \t Total Dis Loss : 0.000727212056517601\n",
      "Steps : 10800, \t Total Gen Loss : 23.154922485351562, \t Total Dis Loss : 0.005289824213832617\n",
      "Steps : 10900, \t Total Gen Loss : 21.197681427001953, \t Total Dis Loss : 0.0025645243003964424\n",
      "Steps : 11000, \t Total Gen Loss : 22.560922622680664, \t Total Dis Loss : 0.0032645908650010824\n",
      "Steps : 11100, \t Total Gen Loss : 22.949281692504883, \t Total Dis Loss : 0.0006821402348577976\n",
      "Steps : 11200, \t Total Gen Loss : 22.01395034790039, \t Total Dis Loss : 0.0017975801602005959\n",
      "Time for epoch 2 is 285.51734614372253 sec\n",
      "Steps : 11300, \t Total Gen Loss : 22.297842025756836, \t Total Dis Loss : 0.0029454929754137993\n",
      "Steps : 11400, \t Total Gen Loss : 21.23322296142578, \t Total Dis Loss : 0.0004424685030244291\n",
      "Steps : 11500, \t Total Gen Loss : 22.65293312072754, \t Total Dis Loss : 0.0033570793457329273\n",
      "Steps : 11600, \t Total Gen Loss : 24.686662673950195, \t Total Dis Loss : 0.0009107389487326145\n",
      "Steps : 11700, \t Total Gen Loss : 19.524646759033203, \t Total Dis Loss : 0.0033572849351912737\n",
      "Steps : 11800, \t Total Gen Loss : 23.40022850036621, \t Total Dis Loss : 0.0019718960393220186\n",
      "Steps : 11900, \t Total Gen Loss : 24.315446853637695, \t Total Dis Loss : 0.0037758166436105967\n",
      "Steps : 12000, \t Total Gen Loss : 21.925081253051758, \t Total Dis Loss : 0.002351584378629923\n",
      "Steps : 12100, \t Total Gen Loss : 20.995832443237305, \t Total Dis Loss : 0.0011334508890286088\n",
      "Steps : 12200, \t Total Gen Loss : 23.772706985473633, \t Total Dis Loss : 0.0015026740729808807\n",
      "Steps : 12300, \t Total Gen Loss : 24.226520538330078, \t Total Dis Loss : 0.001957213506102562\n",
      "Steps : 12400, \t Total Gen Loss : 24.285634994506836, \t Total Dis Loss : 0.002447732025757432\n",
      "Steps : 12500, \t Total Gen Loss : 25.126399993896484, \t Total Dis Loss : 0.0027682494837790728\n",
      "Steps : 12600, \t Total Gen Loss : 20.686918258666992, \t Total Dis Loss : 0.027903802692890167\n",
      "Steps : 12700, \t Total Gen Loss : 26.922040939331055, \t Total Dis Loss : 0.0005272249109111726\n",
      "Steps : 12800, \t Total Gen Loss : 25.611093521118164, \t Total Dis Loss : 0.0009792187483981252\n",
      "Steps : 12900, \t Total Gen Loss : 23.17319107055664, \t Total Dis Loss : 0.0005770393181592226\n",
      "Steps : 13000, \t Total Gen Loss : 22.28416633605957, \t Total Dis Loss : 0.0016823920886963606\n",
      "Steps : 13100, \t Total Gen Loss : 27.709110260009766, \t Total Dis Loss : 0.00045389230945147574\n",
      "Steps : 13200, \t Total Gen Loss : 24.756582260131836, \t Total Dis Loss : 0.0004492096195463091\n",
      "Steps : 13300, \t Total Gen Loss : 21.850505828857422, \t Total Dis Loss : 0.0009806312154978514\n",
      "Steps : 13400, \t Total Gen Loss : 24.81774139404297, \t Total Dis Loss : 0.002143442863598466\n",
      "Steps : 13500, \t Total Gen Loss : 21.136362075805664, \t Total Dis Loss : 0.0011746801901608706\n",
      "Steps : 13600, \t Total Gen Loss : 21.180871963500977, \t Total Dis Loss : 0.0019113689195364714\n",
      "Steps : 13700, \t Total Gen Loss : 24.831987380981445, \t Total Dis Loss : 0.0008762144716456532\n",
      "Steps : 13800, \t Total Gen Loss : 25.325504302978516, \t Total Dis Loss : 0.0018422692082822323\n",
      "Steps : 13900, \t Total Gen Loss : 24.1599063873291, \t Total Dis Loss : 0.0007924809469841421\n",
      "Steps : 14000, \t Total Gen Loss : 24.940597534179688, \t Total Dis Loss : 0.00047775913844816387\n",
      "Steps : 14100, \t Total Gen Loss : 22.748491287231445, \t Total Dis Loss : 0.0006915067788213491\n",
      "Steps : 14200, \t Total Gen Loss : 25.34367561340332, \t Total Dis Loss : 0.0013319012941792607\n",
      "Steps : 14300, \t Total Gen Loss : 20.106582641601562, \t Total Dis Loss : 0.001417116611264646\n",
      "Steps : 14400, \t Total Gen Loss : 22.52220916748047, \t Total Dis Loss : 0.0004629665636457503\n",
      "Steps : 14500, \t Total Gen Loss : 26.774002075195312, \t Total Dis Loss : 0.001253547496162355\n",
      "Steps : 14600, \t Total Gen Loss : 23.322193145751953, \t Total Dis Loss : 0.002183922566473484\n",
      "Steps : 14700, \t Total Gen Loss : 23.06507682800293, \t Total Dis Loss : 0.0034031295217573643\n",
      "Steps : 14800, \t Total Gen Loss : 23.730667114257812, \t Total Dis Loss : 0.0018639451591297984\n",
      "Steps : 14900, \t Total Gen Loss : 20.924448013305664, \t Total Dis Loss : 0.743198573589325\n",
      "Steps : 15000, \t Total Gen Loss : 23.316909790039062, \t Total Dis Loss : 0.006660223472863436\n",
      "Steps : 15100, \t Total Gen Loss : 23.794658660888672, \t Total Dis Loss : 0.00032775162253528833\n",
      "Steps : 15200, \t Total Gen Loss : 27.455429077148438, \t Total Dis Loss : 0.06115203723311424\n",
      "Steps : 15300, \t Total Gen Loss : 23.18109130859375, \t Total Dis Loss : 0.010727087035775185\n",
      "Steps : 15400, \t Total Gen Loss : 21.83058738708496, \t Total Dis Loss : 0.006696528755128384\n",
      "Steps : 15500, \t Total Gen Loss : 19.296831130981445, \t Total Dis Loss : 0.012113838456571102\n",
      "Steps : 15600, \t Total Gen Loss : 18.60296630859375, \t Total Dis Loss : 0.00806146115064621\n",
      "Steps : 15700, \t Total Gen Loss : 23.446502685546875, \t Total Dis Loss : 0.0028391426894813776\n",
      "Steps : 15800, \t Total Gen Loss : 21.45088768005371, \t Total Dis Loss : 0.006524050608277321\n",
      "Steps : 15900, \t Total Gen Loss : 22.6829891204834, \t Total Dis Loss : 0.005666411481797695\n",
      "Steps : 16000, \t Total Gen Loss : 22.402851104736328, \t Total Dis Loss : 0.0013590316521003842\n",
      "Steps : 16100, \t Total Gen Loss : 20.650657653808594, \t Total Dis Loss : 0.000999347772449255\n",
      "Steps : 16200, \t Total Gen Loss : 22.128082275390625, \t Total Dis Loss : 0.005082554649561644\n",
      "Steps : 16300, \t Total Gen Loss : 22.036405563354492, \t Total Dis Loss : 0.0014096935046836734\n",
      "Steps : 16400, \t Total Gen Loss : 22.729007720947266, \t Total Dis Loss : 0.02302853763103485\n",
      "Steps : 16500, \t Total Gen Loss : 25.493335723876953, \t Total Dis Loss : 0.0011698001762852073\n",
      "Steps : 16600, \t Total Gen Loss : 24.181537628173828, \t Total Dis Loss : 0.014950419776141644\n",
      "Steps : 16700, \t Total Gen Loss : 24.604883193969727, \t Total Dis Loss : 0.0013912711292505264\n",
      "Steps : 16800, \t Total Gen Loss : 25.13642692565918, \t Total Dis Loss : 0.0007995879859663546\n",
      "Time for epoch 3 is 285.16479754447937 sec\n",
      "Steps : 16900, \t Total Gen Loss : 23.135848999023438, \t Total Dis Loss : 0.0003543072962202132\n",
      "Steps : 17000, \t Total Gen Loss : 26.66286277770996, \t Total Dis Loss : 0.00026831350987777114\n",
      "Steps : 17100, \t Total Gen Loss : 24.01205062866211, \t Total Dis Loss : 0.00021209463011473417\n",
      "Steps : 17200, \t Total Gen Loss : 23.656864166259766, \t Total Dis Loss : 0.0017220956506207585\n",
      "Steps : 17300, \t Total Gen Loss : 27.709930419921875, \t Total Dis Loss : 0.002049773931503296\n",
      "Steps : 17400, \t Total Gen Loss : 21.20499610900879, \t Total Dis Loss : 0.002354808384552598\n",
      "Steps : 17500, \t Total Gen Loss : 22.424182891845703, \t Total Dis Loss : 0.004475975874811411\n",
      "Steps : 17600, \t Total Gen Loss : 22.339248657226562, \t Total Dis Loss : 0.0027887937612831593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 17700, \t Total Gen Loss : 24.63616180419922, \t Total Dis Loss : 0.0013797483406960964\n",
      "Steps : 17800, \t Total Gen Loss : 22.77141571044922, \t Total Dis Loss : 0.0012469749199226499\n",
      "Steps : 17900, \t Total Gen Loss : 23.44056510925293, \t Total Dis Loss : 0.0012601364869624376\n",
      "Steps : 18000, \t Total Gen Loss : 25.036584854125977, \t Total Dis Loss : 0.00022416969295591116\n",
      "Steps : 18100, \t Total Gen Loss : 22.666587829589844, \t Total Dis Loss : 0.0005528422771021724\n",
      "Steps : 18200, \t Total Gen Loss : 24.222370147705078, \t Total Dis Loss : 0.000584521098062396\n",
      "Steps : 18300, \t Total Gen Loss : 24.70542335510254, \t Total Dis Loss : 0.0006694335024803877\n",
      "Steps : 18400, \t Total Gen Loss : 25.41066551208496, \t Total Dis Loss : 0.0003224338870495558\n",
      "Steps : 18500, \t Total Gen Loss : 25.034574508666992, \t Total Dis Loss : 0.0010606974828988314\n",
      "Steps : 18600, \t Total Gen Loss : 23.37576675415039, \t Total Dis Loss : 0.000211805003345944\n",
      "Steps : 18700, \t Total Gen Loss : 21.18553924560547, \t Total Dis Loss : 0.001617514411918819\n",
      "Steps : 18800, \t Total Gen Loss : 24.985754013061523, \t Total Dis Loss : 0.0007849982939660549\n",
      "Steps : 18900, \t Total Gen Loss : 26.933975219726562, \t Total Dis Loss : 0.00022637589427176863\n",
      "Steps : 19000, \t Total Gen Loss : 20.301101684570312, \t Total Dis Loss : 0.004888938739895821\n",
      "Steps : 19100, \t Total Gen Loss : 26.003576278686523, \t Total Dis Loss : 0.0006191466236487031\n",
      "Steps : 19200, \t Total Gen Loss : 22.84303092956543, \t Total Dis Loss : 0.0030846090521663427\n",
      "Steps : 19300, \t Total Gen Loss : 22.088241577148438, \t Total Dis Loss : 0.0022928882390260696\n",
      "Steps : 19400, \t Total Gen Loss : 20.13191032409668, \t Total Dis Loss : 0.0019239900866523385\n",
      "Steps : 19500, \t Total Gen Loss : 21.4324951171875, \t Total Dis Loss : 0.0016108483541756868\n",
      "Steps : 19600, \t Total Gen Loss : 25.566661834716797, \t Total Dis Loss : 0.0005352570442482829\n",
      "Steps : 19700, \t Total Gen Loss : 22.884279251098633, \t Total Dis Loss : 0.0002658909070305526\n",
      "Steps : 19800, \t Total Gen Loss : 24.301414489746094, \t Total Dis Loss : 0.0003083031333517283\n",
      "Steps : 19900, \t Total Gen Loss : 27.209157943725586, \t Total Dis Loss : 0.0003162992652505636\n",
      "Steps : 20000, \t Total Gen Loss : 22.560806274414062, \t Total Dis Loss : 0.006368403788655996\n",
      "Steps : 20100, \t Total Gen Loss : 22.747615814208984, \t Total Dis Loss : 0.0003476293059065938\n",
      "Steps : 20200, \t Total Gen Loss : 26.08991050720215, \t Total Dis Loss : 0.0002681083569768816\n",
      "Steps : 20300, \t Total Gen Loss : 25.6328182220459, \t Total Dis Loss : 0.000577134545892477\n",
      "Steps : 20400, \t Total Gen Loss : 22.40876007080078, \t Total Dis Loss : 0.00048503183643333614\n",
      "Steps : 20500, \t Total Gen Loss : 24.509445190429688, \t Total Dis Loss : 0.003637220710515976\n",
      "Steps : 20600, \t Total Gen Loss : 23.528892517089844, \t Total Dis Loss : 0.0008975067758001387\n",
      "Steps : 20700, \t Total Gen Loss : 23.323097229003906, \t Total Dis Loss : 0.0016725021414458752\n",
      "Steps : 20800, \t Total Gen Loss : 24.720216751098633, \t Total Dis Loss : 0.0011351137654855847\n",
      "Steps : 20900, \t Total Gen Loss : 21.893848419189453, \t Total Dis Loss : 0.005653118249028921\n",
      "Steps : 21000, \t Total Gen Loss : 19.891761779785156, \t Total Dis Loss : 0.0014727412490174174\n",
      "Steps : 21100, \t Total Gen Loss : 25.08713150024414, \t Total Dis Loss : 0.00021475888206623495\n",
      "Steps : 21200, \t Total Gen Loss : 21.443744659423828, \t Total Dis Loss : 0.000889256305526942\n",
      "Steps : 21300, \t Total Gen Loss : 24.619735717773438, \t Total Dis Loss : 0.0003949740494135767\n",
      "Steps : 21400, \t Total Gen Loss : 22.833913803100586, \t Total Dis Loss : 0.00621948204934597\n",
      "Steps : 21500, \t Total Gen Loss : 22.2656192779541, \t Total Dis Loss : 0.002206578152254224\n",
      "Steps : 21600, \t Total Gen Loss : 23.65536117553711, \t Total Dis Loss : 0.0002974783128593117\n",
      "Steps : 21700, \t Total Gen Loss : 23.29796600341797, \t Total Dis Loss : 0.00118598947301507\n",
      "Steps : 21800, \t Total Gen Loss : 22.0603084564209, \t Total Dis Loss : 0.001391692436300218\n",
      "Steps : 21900, \t Total Gen Loss : 29.22575569152832, \t Total Dis Loss : 0.0026709274388849735\n",
      "Steps : 22000, \t Total Gen Loss : 26.635778427124023, \t Total Dis Loss : 0.006155386101454496\n",
      "Steps : 22100, \t Total Gen Loss : 22.35683250427246, \t Total Dis Loss : 0.0023477699141949415\n",
      "Steps : 22200, \t Total Gen Loss : 27.786958694458008, \t Total Dis Loss : 0.0019918435718864202\n",
      "Steps : 22300, \t Total Gen Loss : 27.56842041015625, \t Total Dis Loss : 0.009149933233857155\n",
      "Steps : 22400, \t Total Gen Loss : 21.473548889160156, \t Total Dis Loss : 0.0008337624021805823\n",
      "Steps : 22500, \t Total Gen Loss : 29.14731216430664, \t Total Dis Loss : 0.005104703363031149\n",
      "Time for epoch 4 is 287.0422420501709 sec\n",
      "Steps : 22600, \t Total Gen Loss : 23.93507957458496, \t Total Dis Loss : 0.004635968711227179\n",
      "Steps : 22700, \t Total Gen Loss : 26.504287719726562, \t Total Dis Loss : 0.000205230011488311\n",
      "Steps : 22800, \t Total Gen Loss : 24.45354652404785, \t Total Dis Loss : 0.0005107539473101497\n",
      "Steps : 22900, \t Total Gen Loss : 26.48212432861328, \t Total Dis Loss : 0.0001868557301349938\n",
      "Steps : 23000, \t Total Gen Loss : 27.754920959472656, \t Total Dis Loss : 0.0001621348492335528\n",
      "Steps : 23100, \t Total Gen Loss : 26.848060607910156, \t Total Dis Loss : 0.00022332099615596235\n",
      "Steps : 23200, \t Total Gen Loss : 27.71189308166504, \t Total Dis Loss : 0.00024755686172284186\n",
      "Steps : 23300, \t Total Gen Loss : 24.855871200561523, \t Total Dis Loss : 0.00032940207165665925\n",
      "Steps : 23400, \t Total Gen Loss : 26.321664810180664, \t Total Dis Loss : 0.0005611213855445385\n",
      "Steps : 23500, \t Total Gen Loss : 29.109689712524414, \t Total Dis Loss : 0.000428281316999346\n",
      "Steps : 23600, \t Total Gen Loss : 26.20696258544922, \t Total Dis Loss : 0.0003374753287062049\n",
      "Steps : 23700, \t Total Gen Loss : 30.69809913635254, \t Total Dis Loss : 0.0007977363420650363\n",
      "Steps : 23800, \t Total Gen Loss : 24.504728317260742, \t Total Dis Loss : 0.00012460451398510486\n",
      "Steps : 23900, \t Total Gen Loss : 27.672143936157227, \t Total Dis Loss : 0.00012464493920560926\n",
      "Steps : 24000, \t Total Gen Loss : 31.93950843811035, \t Total Dis Loss : 0.00041275896364822984\n",
      "Steps : 24100, \t Total Gen Loss : 23.32821273803711, \t Total Dis Loss : 0.031241973862051964\n",
      "Steps : 24200, \t Total Gen Loss : 27.2065486907959, \t Total Dis Loss : 0.0003500121529214084\n",
      "Steps : 24300, \t Total Gen Loss : 26.053136825561523, \t Total Dis Loss : 0.0002560737484600395\n",
      "Steps : 24400, \t Total Gen Loss : 28.107654571533203, \t Total Dis Loss : 0.0002956140087917447\n",
      "Steps : 24500, \t Total Gen Loss : 26.87529182434082, \t Total Dis Loss : 0.00016799024888314307\n",
      "Steps : 24600, \t Total Gen Loss : 26.176372528076172, \t Total Dis Loss : 0.0005456204526126385\n",
      "Steps : 24700, \t Total Gen Loss : 30.74959945678711, \t Total Dis Loss : 0.003102552378550172\n",
      "Steps : 24800, \t Total Gen Loss : 31.25048828125, \t Total Dis Loss : 0.0007902411743998528\n",
      "Steps : 24900, \t Total Gen Loss : 26.14080810546875, \t Total Dis Loss : 0.0016099631320685148\n",
      "Steps : 25000, \t Total Gen Loss : 25.215974807739258, \t Total Dis Loss : 0.000651578651741147\n",
      "Steps : 25100, \t Total Gen Loss : 25.476783752441406, \t Total Dis Loss : 0.0011673307744786143\n",
      "Steps : 25200, \t Total Gen Loss : 25.85263442993164, \t Total Dis Loss : 0.0007249806076288223\n",
      "Steps : 25300, \t Total Gen Loss : 28.733402252197266, \t Total Dis Loss : 0.054251208901405334\n",
      "Steps : 25400, \t Total Gen Loss : 29.544862747192383, \t Total Dis Loss : 0.000370706693502143\n",
      "Steps : 25500, \t Total Gen Loss : 29.043670654296875, \t Total Dis Loss : 0.0015464597381651402\n",
      "Steps : 25600, \t Total Gen Loss : 25.763811111450195, \t Total Dis Loss : 0.0015804218128323555\n",
      "Steps : 25700, \t Total Gen Loss : 27.00289535522461, \t Total Dis Loss : 0.00013638715608976781\n",
      "Steps : 25800, \t Total Gen Loss : 26.80801773071289, \t Total Dis Loss : 0.0026693656109273434\n",
      "Steps : 25900, \t Total Gen Loss : 28.551376342773438, \t Total Dis Loss : 0.0005964020965620875\n",
      "Steps : 26000, \t Total Gen Loss : 26.245681762695312, \t Total Dis Loss : 0.0004033008881378919\n",
      "Steps : 26100, \t Total Gen Loss : 26.099082946777344, \t Total Dis Loss : 0.007516120560467243\n",
      "Steps : 26200, \t Total Gen Loss : 24.459674835205078, \t Total Dis Loss : 0.002267600502818823\n",
      "Steps : 26300, \t Total Gen Loss : 25.54596519470215, \t Total Dis Loss : 0.004335529636591673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps : 26400, \t Total Gen Loss : 26.870819091796875, \t Total Dis Loss : 0.00015712552703917027\n",
      "Steps : 26500, \t Total Gen Loss : 23.715002059936523, \t Total Dis Loss : 0.00041427236283198\n",
      "Steps : 26600, \t Total Gen Loss : 25.96163558959961, \t Total Dis Loss : 0.0004280090215615928\n",
      "Steps : 26700, \t Total Gen Loss : 24.18981170654297, \t Total Dis Loss : 0.0010532104643061757\n",
      "Steps : 26800, \t Total Gen Loss : 26.270965576171875, \t Total Dis Loss : 0.00023123652499634773\n",
      "Steps : 26900, \t Total Gen Loss : 24.298980712890625, \t Total Dis Loss : 0.00041509734001010656\n",
      "Steps : 27000, \t Total Gen Loss : 23.91424560546875, \t Total Dis Loss : 0.00022978364722803235\n",
      "Steps : 27100, \t Total Gen Loss : 29.056568145751953, \t Total Dis Loss : 0.00013229696196503937\n",
      "Steps : 27200, \t Total Gen Loss : 21.315608978271484, \t Total Dis Loss : 0.0016825663624331355\n",
      "Steps : 27300, \t Total Gen Loss : 23.703983306884766, \t Total Dis Loss : 0.0002876531798392534\n",
      "Steps : 27400, \t Total Gen Loss : 22.46372413635254, \t Total Dis Loss : 0.0014482252299785614\n",
      "Steps : 27500, \t Total Gen Loss : 24.057708740234375, \t Total Dis Loss : 0.00016903407231438905\n",
      "Steps : 27600, \t Total Gen Loss : 26.390798568725586, \t Total Dis Loss : 0.0006864981260150671\n",
      "Steps : 27700, \t Total Gen Loss : 22.485563278198242, \t Total Dis Loss : 0.0010539707727730274\n",
      "Steps : 27800, \t Total Gen Loss : 22.87744140625, \t Total Dis Loss : 0.00029738908051513135\n",
      "Steps : 27900, \t Total Gen Loss : 26.08902359008789, \t Total Dis Loss : 0.0003875145339407027\n",
      "Steps : 28000, \t Total Gen Loss : 23.40536880493164, \t Total Dis Loss : 0.0002950996276922524\n",
      "Steps : 28100, \t Total Gen Loss : 22.131017684936523, \t Total Dis Loss : 0.0018748430302366614\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-eea3e1423a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Time for epoch {} is {} sec'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_prefix' is not defined"
     ]
    }
   ],
   "source": [
    "max_epochs = 25\n",
    "steps = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for images, labels in train_dataset:\n",
    "        steps += 1\n",
    "        gen_loss, disc_loss = train_step(images)\n",
    "        \n",
    "        if steps % 100 == 0:\n",
    "            print ('Steps : {}, \\t Total Gen Loss : {}, \\t Total Dis Loss : {}'.format(steps, gen_loss.numpy(), disc_loss.numpy()))\n",
    "        \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    " * 학습 도중 저장된 Checkpoint를 아래와 같이 활용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f9e8dda9f70>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate(test_dataset, set_lambda=0.9):\n",
    "    an_scores = []\n",
    "    gt_labels = []\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(test_dataset):\n",
    "        generated_images = generator(x_batch_train, training=True)\n",
    "        _, feat_real = discriminator(x_batch_train, training=True)\n",
    "        _, feat_fake = discriminator(generated_images, training=True)\n",
    "\n",
    "        generated_images, feat_real, feat_fake = generated_images.numpy(), feat_real.numpy(), feat_fake.numpy()        \n",
    "\n",
    "        rec = abs(x_batch_train - generated_images)\n",
    "        lat = (feat_real - feat_fake) ** 2\n",
    "\n",
    "        rec = tf.reduce_sum(rec, [1,2,3])\n",
    "        lat = tf.reduce_sum(lat, [1,2,3])\n",
    "        \n",
    "        error = (set_lambda * tf.cast(rec, tf.float32)) + ((1 - set_lambda) * tf.cast(lat, tf.float32))\n",
    "        \n",
    "        an_scores.append(error)\n",
    "        gt_labels.append(y_batch_train)\n",
    "        \n",
    "    an_scores = np.concatenate(an_scores, axis=0).reshape([-1])\n",
    "    gt_labels = np.concatenate(gt_labels, axis=0).reshape([-1])\n",
    "    \n",
    "    an_scores = (an_scores - np.amin(an_scores)) / (np.amax(an_scores) - np.amin(an_scores))\n",
    "    \n",
    "    return an_scores, gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 15000\n"
     ]
    }
   ],
   "source": [
    "an_scores, gt_labels = _evaluate(test_dataset)\n",
    "\n",
    "print(len(an_scores), len(gt_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 아래와 같이 테스트 결과를 원래 라벨에 따라 anomaly 데이터와 normal 데이터로 나누어 따로 분석\n",
    " * 라벨에 따라 anomaly score의 분포가 다르게 나타나는지를 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000,)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "normal = []\n",
    "anormaly = []\n",
    "for score, label in zip(an_scores, gt_labels):\n",
    "    if label == 0:\n",
    "        anormaly.append(score)\n",
    "    else:\n",
    "        normal.append(score)\n",
    "\n",
    "normal = np.array(normal)\n",
    "print(normal.shape)\n",
    "anormaly = np.array(anormaly)\n",
    "print(anormaly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normal, bins=np.linspace(0.0, 1.0, num=100))\n",
    "plt.hist(anormaly, bins=np.linspace(0.0, 1.0, num=100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3768786 0.35720283\n",
      "0.13266867 0.1343133\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(normal, norm.pdf(normal, np.mean(normal), np.std(normal)), 'o')\n",
    "plt.plot(anormaly, norm.pdf(anormaly, np.mean(anormaly), np.std(anormaly)), 'o')\n",
    "\n",
    "print(np.mean(normal), np.mean(anormaly))\n",
    "print(np.std(normal), np.std(anormaly))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
